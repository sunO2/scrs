use async_trait::async_trait;
use reqwest::Client;
use std::time::{Duration, Instant};
use tracing::{debug, info, warn, error};
use tokio_stream::StreamExt;
use crate::agent::core::traits::{ModelClient, ModelResponse, ModelError, ModelInfo, ParsedAction};
use crate::agent::llm::types::{ChatRequest, ModelConfig};
use serde::{Deserialize, Serialize};

/// è·å–ç³»ç»Ÿæç¤ºè¯
pub fn get_system_prompt(screen_width: u32, screen_height: u32) -> String {
    let current_date = chrono::Local::now().format("%Yå¹´%mæœˆ%dæ—¥").to_string();
    format!(r#"#
The current date:  {current_date}

# Device Information
- Screen Resolution: {screen_width}x{screen_height}
- Screen Width: {screen_width} pixels
- Screen Height: {screen_height} pixels

# Setup
You are a professional Android operation agent assistant that can fulfill the user's high-level instructions. Given a screenshot of the Android interface at each step, you first analyze the situation, then plan the best course of action using Python-style pseudo-code.

# More details about the code
Your response format must be structured as follows:

Think first: Use <think>...</think> to analyze the current screen, identify key elements, and determine the most efficient action.
Provide the action: Use <answer>...</answer> to return a single line of pseudo-code representing the operation.

Your output should STRICTLY follow the format:
<think>
[Your thought]
</think>
<answer>
[Your operation code]
</answer>

- **Tap**
  Perform a tap action on a specified screen area. The element is a list of 2 integers, representing the coordinates of the tap point.
  **Example**:
  <answer>
  do(action="Tap", element=[x,y])
  </answer>
- **Type**
  Enter text into the currently focused input field.
  **Example**:
  <answer>
  do(action="Type", text="Hello World")
  </answer>
- **Swipe**
  Perform a swipe action with start point and end point.
  **Examples**:
  <answer>
  do(action="Swipe", start=[x1,y1], end=[x2,y2])
  </answer>
- **Long Press**
  Perform a long press action on a specified screen area.
  You can add the element to the action to specify the long press area. The element is a list of 2 integers, representing the coordinates of the long press point.
  **Example**:
  <answer>
  do(action="Long Press", element=[x,y])
  </answer>
- **Launch**
  Launch an app. Try to use launch action when you need to launch an app. Check the instruction to choose the right app before you use this action.
  **Example**:
  <answer>
  do(action="Launch", app="Settings")
  </answer>
- **Back**
  Press the Back button to navigate to the previous screen.
  **Example**:
  <answer>
  do(action="Back")
  </answer>
- **Finish**
  Terminate the program and optionally print a message.
  **Example**:
  <answer>
  finish(message="Task completed.")
  </answer>


REMEMBER:
- Think before you act: Always analyze the current UI and the best course of action before executing any step, and output in <think> part.
- Only ONE LINE of action in <answer> part per response: Each step must contain exactly one line of executable code.
- Generate execution code strictly according to format requirements."#,)
}

/// AutoGLM æµå¼å“åº”çš„å¢é‡æ•°æ®
#[derive(Debug, Deserialize)]
#[serde(tag = "type")]
enum StreamEvent {
    #[serde(rename = "token")]
    Token { token: String },
    #[serde(rename = "message_end")]
    MessageEnd,
}

/// AutoGLM æ€§èƒ½æŒ‡æ ‡
#[derive(Debug, Clone, Serialize)]
pub struct PerformanceMetrics {
    /// é¦–ä¸ª token æ—¶é—´ï¼ˆç§’ï¼‰
    pub time_to_first_token: Option<f64>,
    /// æ€è€ƒç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰
    pub time_to_thinking_end: Option<f64>,
    /// æ€»æ¨ç†æ—¶é—´ï¼ˆç§’ï¼‰
    pub total_time: f64,
}

/// AutoGLM å®¢æˆ·ç«¯ï¼Œæ”¯æŒæµå¼å“åº”å’Œç‰¹æ®Šæ ‡è®°è§£æ
pub struct AutoGLMClient {
    client: Client,
    config: ModelConfig,
}

impl AutoGLMClient {
    /// åˆ›å»ºæ–°çš„ AutoGLM å®¢æˆ·ç«¯
    pub fn new(config: ModelConfig) -> Result<Self, ModelError> {
        info!("åˆ›å»º AutoGLM å®¢æˆ·ç«¯: {}", config.model_name);
        info!("  API ç«¯ç‚¹: {}", config.base_url);
        info!("  è¶…æ—¶æ—¶é—´: {}s", config.timeout);
        info!("  API Key: {}...", &config.api_key[..config.api_key.len().min(10)]);

        let client = Client::builder()
            .timeout(Duration::from_secs(config.timeout))
            .connect_timeout(Duration::from_secs(30))
            .pool_idle_timeout(Duration::from_secs(120))
            .tcp_keepalive(Duration::from_secs(600))
            .build()
            .map_err(|e| ModelError::ApiError(format!("åˆ›å»º HTTP å®¢æˆ·ç«¯å¤±è´¥: {}", e)))?;

        Ok(Self { client, config })
    }

    /// å‘é€æµå¼èŠå¤©è¯·æ±‚
    async fn send_stream_request(&self, request: ChatRequest) -> Result<String, ModelError> {
        let url = format!("{}/chat/completions", self.config.base_url);

        debug!("å‘é€ AutoGLM æµå¼è¯·æ±‚åˆ°: {}", url);

        let mut stream_request = request.clone();
        stream_request.stream = Some(true);

        let response = self
            .client
            .post(&url)
            .header("Authorization", format!("Bearer {}", self.config.api_key))
            .header("Content-Type", "application/json")
            .json(&stream_request)
            .send()
            .await
            .map_err(|e| ModelError::NetworkError(format!("å‘é€è¯·æ±‚å¤±è´¥: {}", e)))?;

        let status = response.status();

        if !status.is_success() {
            let error_text = response
                .text()
                .await
                .unwrap_or_else(|_| "æ— æ³•è¯»å–é”™è¯¯å“åº”".to_string());

            error!("AutoGLM è¯·æ±‚å¤±è´¥: {} - {}", status, error_text);

            if status.as_u16() == 401 {
                return Err(ModelError::InvalidApiKey);
            }

            if status.as_u16() == 429 {
                return Err(ModelError::RateLimit);
            }

            return Err(ModelError::ApiError(format!(
                "è¯·æ±‚å¤±è´¥: {} - {}",
                status, error_text
            )));
        }

        // å¤„ç†æµå¼å“åº”
        let mut full_content = String::new();
        let mut byte_stream = response.bytes_stream();

        while let Some(chunk_result) = byte_stream.next().await {
            let chunk = chunk_result
                .map_err(|e| ModelError::NetworkError(format!("è¯»å–æµæ•°æ®å¤±è´¥: {}", e)))?;

            let chunk_str = String::from_utf8_lossy(&chunk);
            full_content.push_str(&chunk_str);
        }

        Ok(full_content)
    }

    /// å‘é€éæµå¼èŠå¤©è¯·æ±‚
    async fn send_request(&self, request: ChatRequest) -> Result<ChatResponse, ModelError> {
        let url = format!("{}/chat/completions", self.config.base_url);

        info!("å‘é€ AutoGLM è¯·æ±‚åˆ°: {}", url);
        info!("  æ¨¡å‹: {}", request.model);
        info!("  æ¶ˆæ¯æ•°: {}", request.messages.len());

        // å‘é€è¯·æ±‚å¹¶å¤„ç†é”™è¯¯
        match self._send_request(&url, &request).await {
            Ok(response) => Ok(response),
            Err(e) => {
                error!("AutoGLM è¯·æ±‚å¤±è´¥: {}", e);
                error!("è¯·æ£€æŸ¥:");
                error!("  1. API Key æ˜¯å¦æ­£ç¡®è®¾ç½®");
                error!("  2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸");
                error!("  3. API ç«¯ç‚¹æ˜¯å¦å¯è®¿é—®: {}", self.config.base_url);
                error!("  4. æ˜¯å¦æœ‰è¶³å¤Ÿçš„é…é¢");
                Err(e)
            }
        }
    }

    async fn _send_request(&self, url: &str, request: &ChatRequest) -> Result<ChatResponse, ModelError> {
        // æ‰“å°è¯·æ±‚è¯¦æƒ…ï¼ˆé€‰æ‹©æ€§è¾“å‡ºï¼Œè¿‡æ»¤å›¾ç‰‡æ•°æ®ï¼‰
        info!("========== AutoGLM è¯·æ±‚ ==========");
        info!("URL: {}", url);
        info!("æ¨¡å‹: {}", request.model);
        info!("å‚æ•°: max_tokens={:?}, temperature={:?}, top_p={:?}, stream={:?}",
            request.max_tokens, request.temperature, request.top_p, request.stream);
        info!("æ¶ˆæ¯æ•°é‡: {}", request.messages.len());
        info!("================================");

        let response = self
            .client
            .post(url)
            .header("Authorization", format!("Bearer {}", self.config.api_key))
            .header("Content-Type", "application/json")
            .json(request)
            .send()
            .await
            .map_err(|e| {
                error!("ç½‘ç»œè¯·æ±‚é”™è¯¯: {}", e);
                ModelError::NetworkError(format!("å‘é€è¯·æ±‚å¤±è´¥: {}", e))
            })?;

        let status = response.status();
        debug!("å“åº”çŠ¶æ€: {}", status);

        let response_text = response
            .text()
            .await
            .map_err(|e| ModelError::NetworkError(format!("è¯»å–å“åº”å¤±è´¥: {}", e)))?;

        // æ‰“å°å“åº”è¯¦æƒ…
        info!("========== AutoGLM å“åº” ==========");
        info!("çŠ¶æ€ç : {}", status);
        info!("å“åº”ä½“ ({} å­—èŠ‚):", response_text.len());
        info!("================================");

        if !status.is_success() {
            warn!("AutoGLM è¯·æ±‚å¤±è´¥: {} - {}", status, response_text);

            if status.as_u16() == 401 {
                error!("API Key æ— æ•ˆ");
                return Err(ModelError::InvalidApiKey);
            }

            if status.as_u16() == 429 {
                error!("è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè§¦å‘é™æµ");
                return Err(ModelError::RateLimit);
            }

            return Err(ModelError::ApiError(format!(
                "è¯·æ±‚å¤±è´¥: {} - {}",
                status, response_text
            )));
        }

        let chat_response: ChatResponse = serde_json::from_str(&response_text).map_err(|e| {
            warn!("è§£æ AutoGLM å“åº”å¤±è´¥: {}", e);
            warn!("å“åº”å†…å®¹: {}", &response_text);
            ModelError::ParseError(format!("è§£æå“åº”å¤±è´¥: {}", e))
        })?;

        Ok(chat_response)
    }

    /// è§£æ AutoGLM å“åº”ï¼ˆæ”¯æŒç‰¹æ®Šæ ‡è®°ï¼‰
    ///
    /// è§£æè§„åˆ™ï¼ˆä¸¥æ ¼æŒ‰ç…§ Python ä»£ç ï¼‰ï¼š
    /// 1. å¦‚æœåŒ…å« 'finish(message='ï¼Œä¹‹å‰çš„æ˜¯ thinkingï¼Œä½¿ç”¨ parser è§£æ action
    /// 2. å¦‚æœåŒ…å« 'do(action='ï¼Œä¹‹å‰çš„æ˜¯ thinkingï¼Œä½¿ç”¨ parser è§£æ action
    /// 3. å¦‚æœåŒ…å« '<answer>'ï¼Œä½¿ç”¨ XML æ ‡ç­¾è§£æï¼Œç„¶åç”¨ parser è§£æ action
    /// 4. å¦åˆ™ï¼Œthinking ä¸ºç©ºï¼Œå°è¯•ç”¨ parser è§£æå…¨éƒ¨å†…å®¹
    fn parse_response(&self, content: &str) -> (String, Option<ParsedAction>) {
        use crate::agent::llm::parser::{try_parse_do_action, try_parse_finish_action, parse_action_from_response};

        // è§„åˆ™ 1: æ£€æŸ¥ finish(message=
        if let Some(pos) = content.find("finish(message=") {
            let thinking = content[..pos].trim().to_string();
            let action_str = "finish(message=".to_string() + &content[pos + 16..];

            // ä½¿ç”¨ parser è§£æ finish action
            if let Some(action) = try_parse_finish_action(&action_str) {
                return (thinking, Some(action));
            }
            // å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹ action å­—ç¬¦ä¸²
            let action = ParsedAction {
                action_type: "raw".to_string(),
                parameters: serde_json::json!({ "raw": action_str }),
                reasoning: action_str.clone(),
            };
            return (thinking, Some(action));
        }

        // è§„åˆ™ 2: æ£€æŸ¥ do(action=
        if let Some(pos) = content.find("do(action=") {
            let thinking = content[..pos].trim().to_string();
            let action_str = "do(action=".to_string() + &content[pos + 10..];

            // ä½¿ç”¨ parser è§£æ do action
            if let Some(action) = try_parse_do_action(&action_str) {
                return (thinking, Some(action));
            }
            // å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹ action å­—ç¬¦ä¸²
            let action = ParsedAction {
                action_type: "raw".to_string(),
                parameters: serde_json::json!({ "raw": action_str }),
                reasoning: action_str.clone(),
            };
            return (thinking, Some(action));
        }

        // è§„åˆ™ 3: å›é€€åˆ° XML æ ‡ç­¾è§£æ
        // Python ä»£ç : thinking = parts[0].replace("<thinking>", "").replace("</thinking>", "").strip()
        if let Some(start) = content.find("<answer>") {
            if let Some(end) = content.find("</answer>") {
                // æå– <answer> ä¹‹å‰çš„å†…å®¹ä½œä¸º thinking
                let thinking_raw = &content[..start];
                // ç§»é™¤ <thinking> å’Œ </thinking> æ ‡ç­¾ï¼ˆåªç§»é™¤æ ‡ç­¾ï¼Œä¿ç•™ä¸­é—´å†…å®¹ï¼‰
                let thinking = thinking_raw
                    .replace("<thinking>", "")
                    .replace("</thinking>", "")
                    .trim()
                    .to_string();
                let action_content = content[start + 8..end].to_string(); // 8 = len("<answer>")

                // å°è¯•è§£æ action
                if let Ok(Some(action)) = parse_action_from_response(&action_content) {
                    return (thinking, Some(action));
                }

                // å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹ action å­—ç¬¦ä¸²
                let action = ParsedAction {
                    action_type: "raw".to_string(),
                    parameters: serde_json::json!({ "raw": action_content }),
                    reasoning: action_content,
                };
                return (thinking, Some(action));
            }
        }

        // è§„åˆ™ 4: æ²¡æœ‰æ‰¾åˆ°æ ‡è®°ï¼Œthinking ä¸ºç©ºï¼Œå°è¯•ç”¨ parser è§£æå…¨éƒ¨å†…å®¹
        if let Ok(Some(action)) = parse_action_from_response(content) {
            return (String::new(), Some(action));
        }

        // å¦‚æœæ‰€æœ‰è§£æéƒ½å¤±è´¥ï¼Œè¿”å›åŸå§‹å†…å®¹ä½œä¸º action
        let action = ParsedAction {
            action_type: "raw".to_string(),
            parameters: serde_json::json!({ "raw": content }),
            reasoning: content.to_string(),
        };
        (String::new(), Some(action))
    }

}

#[async_trait]
impl ModelClient for AutoGLMClient {
    async fn query_with_messages(
        &self,
        messages: Vec<crate::agent::core::traits::ChatMessage>,
        screenshot: Option<&str>,
    ) -> Result<ModelResponse, ModelError> {
        debug!("æŸ¥è¯¢ AutoGLMï¼Œæ¶ˆæ¯æ•°é‡: {}", messages.len());

        let start_time = Instant::now();

        // è½¬æ¢æ¶ˆæ¯æ ¼å¼
        let mut api_messages = vec![];

        // æ‰¾åˆ°æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯çš„ç´¢å¼•ï¼ˆç”¨äºæ·»åŠ æˆªå›¾ï¼‰
        let last_user_msg_index = messages.iter().rposition(|msg| {
            matches!(msg.role, crate::agent::core::traits::MessageRole::User)
        });

        for (idx, msg) in messages.iter().enumerate() {
            let role = match msg.role {
                crate::agent::core::traits::MessageRole::System => {
                    crate::agent::llm::types::MessageRole::System
                }
                crate::agent::core::traits::MessageRole::User => {
                    crate::agent::llm::types::MessageRole::User
                }
                crate::agent::core::traits::MessageRole::Assistant => {
                    crate::agent::llm::types::MessageRole::Assistant
                }
            };

            // åªåœ¨æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ä¸­æ·»åŠ æˆªå›¾
            let is_last_user_msg = last_user_msg_index == Some(idx);

            let content = if is_last_user_msg && screenshot.is_some() {
                crate::agent::llm::types::MessageContent::Multimodal(vec![
                    crate::agent::llm::types::ContentBlock {
                        block_type: "image_url".to_string(),
                        text: None,
                        image_url: Some(crate::agent::llm::types::ImageUrl::from_base64(screenshot.unwrap())),
                    },
                    crate::agent::llm::types::ContentBlock {
                        block_type: "text".to_string(),
                        text: Some(msg.content.clone()),
                        image_url: None,
                    },
                ])
            } else {
                crate::agent::llm::types::MessageContent::Text(msg.content.clone())
            };

            api_messages.push(crate::agent::llm::types::ChatMessage { role, content });
        }

        // æ„å»ºè¯·æ±‚
        let request = ChatRequest {
            model: self.config.model_name.clone(),
            messages: api_messages,
            max_tokens: Some(self.config.max_tokens),
            temperature: Some(self.config.temperature),
            top_p: Some(self.config.top_p),
            stream: Some(false),
        };

        // å‘é€è¯·æ±‚
        let chat_response = self.send_request(request).await?;

        // è§£æå“åº”
        let choice = chat_response.choices.first().ok_or_else(|| {
            ModelError::ParseError("å“åº”ä¸­æ²¡æœ‰é€‰æ‹©é¡¹".to_string())
        })?;

        let content = match &choice.message.content {
            crate::agent::llm::types::MessageContent::Text(text) => text.clone(),
            _ => "".to_string(),
        };

        let total_time = start_time.elapsed().as_secs_f64();

        // ä½¿ç”¨ AutoGLM ç‰¹æ®Šè§£æ
        let (thinking, parsed_action) = self.parse_response(&content);

        let usage = chat_response.usage.unwrap_or(Usage {
            prompt_tokens: 0,
            completion_tokens: 0,
            total_tokens: 0,
        });

        // æ‰“å°æ€§èƒ½æŒ‡æ ‡
        info!("ğŸ“Š AutoGLM æ€§èƒ½æŒ‡æ ‡:");
        info!("   æ€»æ¨ç†æ—¶é—´: {:.3}s", total_time);
        info!("   ä½¿ç”¨ tokens: {}", usage.total_tokens);
        info!("   æ€è€ƒè¿‡ç¨‹: {}", &content);

        Ok(ModelResponse {
            content: content.clone(),
            action: parsed_action,
            confidence: 0.8,
            reasoning: if thinking.is_empty() { None } else { Some(thinking) },
            tokens_used: usage.total_tokens,
        })
    }

    fn info(&self) -> ModelInfo {
        ModelInfo {
            name: self.config.model_name.clone(),
            provider: self.config.provider.clone(),
            supports_vision: true,
            max_tokens: self.config.max_tokens,
            context_window: 8192, // AutoGLM-Phone-9B çš„ä¸Šä¸‹æ–‡çª—å£
        }
    }
}

/// ChatResponse ç±»å‹ï¼ˆå¦‚æœæœªåœ¨ types.rs ä¸­å®šä¹‰ï¼‰
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChatResponse {
    pub id: Option<String>,
    pub object: Option<String>,
    pub created: Option<u64>,
    pub model: Option<String>,
    pub choices: Vec<Choice>,
    pub usage: Option<Usage>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Choice {
    pub index: usize,
    pub message: crate::agent::llm::types::ChatMessage,
    pub finish_reason: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Usage {
    pub prompt_tokens: u32,
    pub completion_tokens: u32,
    pub total_tokens: u32,
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_parse_finish_action() {
        let client = AutoGLMClient::new(ModelConfig::default()).unwrap();
        let response = r#"Thinking...
finish(message="Task completed successfully")"#;

        let (thinking, action) = client.parse_response(response);

        // éªŒè¯ thinking éƒ¨åˆ†
        assert_eq!(thinking, "Thinking...");

        // éªŒè¯ action è§£ææˆåŠŸ
        assert!(action.is_some());
        let action = action.unwrap();
        assert_eq!(action.action_type, "finish");
        assert_eq!(action.parameters.get("result").unwrap().as_str().unwrap(), "Task completed successfully");
    }

    #[test]
    fn test_parse_do_action() {
        let client = AutoGLMClient::new(ModelConfig::default()).unwrap();
        let response = r#"Analyzing screen...
do(action="Tap", element=[500, 800])"#;

        let (thinking, action) = client.parse_response(response);

        // éªŒè¯ thinking éƒ¨åˆ†
        assert_eq!(thinking, "Analyzing screen...");

        // éªŒè¯ action è§£ææˆåŠŸ
        assert!(action.is_some());
        let action = action.unwrap();
        assert_eq!(action.action_type, "tap");
        // element åº”è¯¥è¢«è§£æä¸ºæ•°ç»„
        assert!(action.parameters.get("element").is_some());
    }

    #[test]
    fn test_parse_xml_answer_with_json() {
        let client = AutoGLMClient::new(ModelConfig::default()).unwrap();
        let response = r#"<thinking>I should tap the button</thinking>
<answer>{"action_type": "tap", "x": 100, "y": 200}</answer>"#;

        let (thinking, action) = client.parse_response(response);

        // éªŒè¯ thinking éƒ¨åˆ†ï¼ˆç§»é™¤ <thinking> æ ‡ç­¾åï¼‰
        assert_eq!(thinking.trim(), "I should tap the button");

        // éªŒè¯ action è§£ææˆåŠŸ
        assert!(action.is_some());
        let action = action.unwrap();
        assert_eq!(action.action_type, "tap");
        assert_eq!(action.parameters.get("x").unwrap().as_u64().unwrap(), 100);
        assert_eq!(action.parameters.get("y").unwrap().as_u64().unwrap(), 200);
    }

    #[test]
    fn test_parse_no_markers() {
        let client = AutoGLMClient::new(ModelConfig::default()).unwrap();
        let response = r#"Some random text without markers"#;

        let (thinking, action) = client.parse_response(response);

        // è§„åˆ™ 4: thinking åº”è¯¥ä¸ºç©º
        assert!(thinking.is_empty());

        // æ— æ³•è§£æçš„å†…å®¹è¿”å› raw
        assert!(action.is_some());
        let action = action.unwrap();
        assert_eq!(action.action_type, "raw");
        assert_eq!(action.reasoning, "Some random text without markers");
    }

    #[test]
    fn test_parse_priority() {
        let client = AutoGLMClient::new(ModelConfig::default()).unwrap();

        // finish(message= ä¼˜å…ˆçº§æœ€é«˜
        let response1 = r#"Text...
do(action=tap)
finish(message="done")"#;
        let (thinking, action) = client.parse_response(response1);
        assert!(thinking.contains("Text..."));
        assert_eq!(action.unwrap().action_type, "finish");

        // do(action= ç¬¬äºŒä¼˜å…ˆçº§
        let response2 = r#"<thinking>Thought</thinking>
<answer>answer content</answer>
do(action="Launch", app="å¾®ä¿¡")"#;
        let (_thinking, action) = client.parse_response(response2);
        assert_eq!(action.unwrap().action_type, "launch");
    }

    #[test]
    fn test_parse_do_action_launch() {
        let client = AutoGLMClient::new(ModelConfig::default()).unwrap();
        let response = r#"I need to open WeChat.
do(action="Launch", app="å¾®ä¿¡")"#;

        let (thinking, action) = client.parse_response(response);

        assert_eq!(thinking, "I need to open WeChat.");
        assert!(action.is_some());
        let action = action.unwrap();
        assert_eq!(action.action_type, "launch");
        assert_eq!(action.parameters.get("app").unwrap().as_str().unwrap(), "å¾®ä¿¡");
    }

    #[test]
    fn test_parse_do_action_wait() {
        let client = AutoGLMClient::new(ModelConfig::default()).unwrap();
        let response = r#"åº”ç”¨æ­£åœ¨åŠ è½½ä¸­
do(action="Wait", duration=1, message="åº”ç”¨æ­£åœ¨åŠ è½½ä¸­ï¼Œè¯·ç¨ç­‰ã€‚")"#;

        let (thinking, action) = client.parse_response(response);

        assert_eq!(thinking, "åº”ç”¨æ­£åœ¨åŠ è½½ä¸­");
        assert!(action.is_some());
        let action = action.unwrap();
        assert_eq!(action.action_type, "wait");
        assert_eq!(action.parameters.get("duration").unwrap().as_u64().unwrap(), 1);
        assert_eq!(action.parameters.get("message").unwrap().as_str().unwrap(), "åº”ç”¨æ­£åœ¨åŠ è½½ä¸­ï¼Œè¯·ç¨ç­‰ã€‚");
    }
}
