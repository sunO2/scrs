use async_trait::async_trait;
use reqwest::Client;
use std::time::{Duration, Instant};
use tracing::{debug, info, warn, error};
use tokio_stream::StreamExt;
use crate::agent::core::traits::{ModelClient, ModelResponse, ModelError, ModelInfo};
use crate::agent::llm::types::{ChatRequest, ModelConfig};
use serde::{Deserialize, Serialize};

// å¯¼å…¥ ActionEnum ç”¨äºè§£æå“åº”
use crate::agent::actions::base::ActionEnum;

/// è·å–ç³»ç»Ÿæç¤ºè¯
pub fn get_system_prompt(screen_width: u32, screen_height: u32) -> String {
    let current_date = chrono::Local::now().format("%Yå¹´%mæœˆ%dæ—¥").to_string();
    format!(r#"#
The current date:  {current_date}

# Device Information
- Screen Resolution: {screen_width}x{screen_height}
- Screen Width: {screen_width} pixels
- Screen Height: {screen_height} pixels

# Setup
You are a professional Android operation agent assistant that can fulfill the user's high-level instructions. Given a screenshot of the Android interface at each step, you first analyze the situation, then plan the best course of action using Python-style pseudo-code.

# More details about the code
Your response format must be structured as follows:

Think first: Use <think>...</think> to analyze the current screen, identify key elements, and determine the most efficient action.
Provide the action: Use <answer>...</answer> to return a single line of pseudo-code representing the operation.

Your output should STRICTLY follow the format:
<think>
[Your thought]
</think>
<answer>
[Your operation code]
</answer>

- **Tap**
  Perform a tap action on a specified screen area. The element is a list of 2 integers, representing the coordinates of the tap point.
  **Example**:
  <answer>
  do(action="Tap", element=[x,y])
  </answer>
- **Type**
  Enter text into the currently focused input field.
  **Example**:
  <answer>
  do(action="Type", text="Hello World")
  </answer>
- **Swipe**
  Perform a swipe action with start point and end point.
  **Examples**:
  <answer>
  do(action="Swipe", start=[x1,y1], end=[x2,y2])
  </answer>
- **Long Press**
  Perform a long press action on a specified screen area.
  You can add the element to the action to specify the long press area. The element is a list of 2 integers, representing the coordinates of the long press point.
  **Example**:
  <answer>
  do(action="Long Press", element=[x,y])
  </answer>
- **Launch**
  Launch an app. Try to use launch action when you need to launch an app. Check the instruction to choose the right app before you use this action.
  **Example**:
  <answer>
  do(action="Launch", app="Settings")
  </answer>
- **Back**
  Press the Back button to navigate to the previous screen.
  **Example**:
  <answer>
  do(action="Back")
  </answer>
- **Finish**
  Terminate the program and optionally print a message.
  **Example**:
  <answer>
  finish(message="Task completed.")
  </answer>


REMEMBER:
- Think before you act: Always analyze the current UI and the best course of action before executing any step, and output in <think> part.
- Only ONE LINE of action in <answer> part per response: Each step must contain exactly one line of executable code.
- Generate execution code strictly according to format requirements."#,)
}

/// AutoGLM æµå¼å“åº”çš„å¢é‡æ•°æ®
#[derive(Debug, Deserialize)]
#[serde(tag = "type")]
enum StreamEvent {
    #[serde(rename = "token")]
    Token { token: String },
    #[serde(rename = "message_end")]
    MessageEnd,
}

/// AutoGLM æ€§èƒ½æŒ‡æ ‡
#[derive(Debug, Clone, Serialize)]
pub struct PerformanceMetrics {
    /// é¦–ä¸ª token æ—¶é—´ï¼ˆç§’ï¼‰
    pub time_to_first_token: Option<f64>,
    /// æ€è€ƒç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰
    pub time_to_thinking_end: Option<f64>,
    /// æ€»æ¨ç†æ—¶é—´ï¼ˆç§’ï¼‰
    pub total_time: f64,
}

/// AutoGLM å®¢æˆ·ç«¯ï¼Œæ”¯æŒæµå¼å“åº”å’Œç‰¹æ®Šæ ‡è®°è§£æ
pub struct AutoGLMClient {
    client: Client,
    config: ModelConfig,
}

impl AutoGLMClient {
    /// åˆ›å»ºæ–°çš„ AutoGLM å®¢æˆ·ç«¯
    pub fn new(config: ModelConfig) -> Result<Self, ModelError> {
        info!("åˆ›å»º AutoGLM å®¢æˆ·ç«¯: {}", config.model_name);
        info!("  API ç«¯ç‚¹: {}", config.base_url);
        info!("  è¶…æ—¶æ—¶é—´: {}s", config.timeout);
        info!("  API Key: {}...", &config.api_key[..config.api_key.len().min(10)]);

        let client = Client::builder()
            .timeout(Duration::from_secs(config.timeout))
            .connect_timeout(Duration::from_secs(30))
            .pool_idle_timeout(Duration::from_secs(120))
            .tcp_keepalive(Duration::from_secs(600))
            .build()
            .map_err(|e| ModelError::ApiError(format!("åˆ›å»º HTTP å®¢æˆ·ç«¯å¤±è´¥: {}", e)))?;

        Ok(Self { client, config })
    }

    /// å‘é€æµå¼èŠå¤©è¯·æ±‚
    async fn send_stream_request(&self, request: ChatRequest) -> Result<String, ModelError> {
        let url = format!("{}/chat/completions", self.config.base_url);

        debug!("å‘é€ AutoGLM æµå¼è¯·æ±‚åˆ°: {}", url);

        let mut stream_request = request.clone();
        stream_request.stream = Some(true);

        let response = self
            .client
            .post(&url)
            .header("Authorization", format!("Bearer {}", self.config.api_key))
            .header("Content-Type", "application/json")
            .json(&stream_request)
            .send()
            .await
            .map_err(|e| ModelError::NetworkError(format!("å‘é€è¯·æ±‚å¤±è´¥: {}", e)))?;

        let status = response.status();

        if !status.is_success() {
            let error_text = response
                .text()
                .await
                .unwrap_or_else(|_| "æ— æ³•è¯»å–é”™è¯¯å“åº”".to_string());

            error!("AutoGLM è¯·æ±‚å¤±è´¥: {} - {}", status, error_text);

            if status.as_u16() == 401 {
                return Err(ModelError::InvalidApiKey);
            }

            if status.as_u16() == 429 {
                return Err(ModelError::RateLimit);
            }

            return Err(ModelError::ApiError(format!(
                "è¯·æ±‚å¤±è´¥: {} - {}",
                status, error_text
            )));
        }

        // å¤„ç†æµå¼å“åº”
        let mut full_content = String::new();
        let mut byte_stream = response.bytes_stream();

        while let Some(chunk_result) = byte_stream.next().await {
            let chunk = chunk_result
                .map_err(|e| ModelError::NetworkError(format!("è¯»å–æµæ•°æ®å¤±è´¥: {}", e)))?;

            let chunk_str = String::from_utf8_lossy(&chunk);
            full_content.push_str(&chunk_str);
        }

        Ok(full_content)
    }

    /// å‘é€éæµå¼èŠå¤©è¯·æ±‚
    async fn send_request(&self, request: ChatRequest) -> Result<ChatResponse, ModelError> {
        let url = format!("{}/chat/completions", self.config.base_url);

        info!("å‘é€ AutoGLM è¯·æ±‚åˆ°: {}", url);
        info!("  æ¨¡å‹: {}", request.model);
        info!("  æ¶ˆæ¯æ•°: {}", request.messages.len());

        // å‘é€è¯·æ±‚å¹¶å¤„ç†é”™è¯¯
        match self._send_request(&url, &request).await {
            Ok(response) => Ok(response),
            Err(e) => {
                error!("AutoGLM è¯·æ±‚å¤±è´¥: {}", e);
                error!("è¯·æ£€æŸ¥:");
                error!("  1. API Key æ˜¯å¦æ­£ç¡®è®¾ç½®");
                error!("  2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸");
                error!("  3. API ç«¯ç‚¹æ˜¯å¦å¯è®¿é—®: {}", self.config.base_url);
                error!("  4. æ˜¯å¦æœ‰è¶³å¤Ÿçš„é…é¢");
                Err(e)
            }
        }
    }

    async fn _send_request(&self, url: &str, request: &ChatRequest) -> Result<ChatResponse, ModelError> {
        // æ‰“å°è¯·æ±‚è¯¦æƒ…ï¼ˆé€‰æ‹©æ€§è¾“å‡ºï¼Œè¿‡æ»¤å›¾ç‰‡æ•°æ®ï¼‰
        info!("========== AutoGLM è¯·æ±‚ ==========");
        info!("URL: {}", url);
        info!("æ¨¡å‹: {}", request.model);
        info!("å‚æ•°: max_tokens={:?}, temperature={:?}, top_p={:?}, stream={:?}",
            request.max_tokens, request.temperature, request.top_p, request.stream);
        info!("æ¶ˆæ¯æ•°é‡: {}", request.messages.len());
        info!("================================");

        let response = self
            .client
            .post(url)
            .header("Authorization", format!("Bearer {}", self.config.api_key))
            .header("Content-Type", "application/json")
            .json(request)
            .send()
            .await
            .map_err(|e| {
                error!("ğŸ”´ AutoGLM ç½‘ç»œè¯·æ±‚å¤±è´¥");
                error!("   URL: {}", url);
                error!("   é”™è¯¯ç±»å‹: {:?}", e);

                // æä¾›æ›´è¯¦ç»†çš„è¯Šæ–­ä¿¡æ¯
                if e.is_timeout() {
                    error!("   é”™è¯¯: è¯·æ±‚è¶…æ—¶");
                    error!("   å¯èƒ½çš„åŸå› :");
                    error!("   1. ç½‘ç»œè¿æ¥ä¸ç¨³å®š");
                    error!("   2. API æœåŠ¡å™¨å“åº”ç¼“æ…¢");
                    error!("   3. è¯·æ±‚å¤ªå¤§ï¼Œå¤„ç†æ—¶é—´è¿‡é•¿");
                    error!("   å»ºè®®:");
                    error!("   - æ£€æŸ¥ç½‘ç»œè¿æ¥");
                    error!("   - å¢åŠ  timeout æ—¶é—´");
                    error!("   - å‡å°è¯·æ±‚å¤§å°ï¼ˆå¦‚å‡å°‘å›¾ç‰‡æ•°é‡ï¼‰");
                } else if e.is_connect() {
                    error!("   é”™è¯¯: æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨");
                    error!("   å¯èƒ½çš„åŸå› :");
                    error!("   1. ç½‘ç»œæœªè¿æ¥");
                    error!("   2. API æœåŠ¡å™¨åœ°å€é”™è¯¯: {}", url);
                    error!("   3. é˜²ç«å¢™æˆ–ä»£ç†é˜»æ­¢è¿æ¥");
                    error!("   4. DNS è§£æå¤±è´¥");
                    error!("   å»ºè®®:");
                    error!("   - æ£€æŸ¥ç½‘ç»œè¿æ¥");
                    error!("   - éªŒè¯ API URL æ˜¯å¦æ­£ç¡®");
                    error!("   - æ£€æŸ¥é˜²ç«å¢™è®¾ç½®");
                    error!("   - å°è¯•ä½¿ç”¨ VPN");
                } else {
                    error!("   å…¶ä»–ç½‘ç»œé”™è¯¯");
                    error!("   åŸå§‹é”™è¯¯: {}", e);
                }

                ModelError::NetworkError(format!("å‘é€è¯·æ±‚å¤±è´¥: {}", e))
            })?;

        let status = response.status();
        debug!("å“åº”çŠ¶æ€: {}", status);

        let response_text = response
            .text()
            .await
            .map_err(|e| ModelError::NetworkError(format!("è¯»å–å“åº”å¤±è´¥: {}", e)))?;

        // æ‰“å°å“åº”è¯¦æƒ…
        info!("========== AutoGLM å“åº” ==========");
        info!("çŠ¶æ€ç : {}", status);
        info!("å“åº”ä½“ ({} å­—èŠ‚):", response_text.len());
        info!("================================");

        if !status.is_success() {
            warn!("AutoGLM è¯·æ±‚å¤±è´¥: {} - {}", status, response_text);

            if status.as_u16() == 401 {
                error!("API Key æ— æ•ˆ");
                return Err(ModelError::InvalidApiKey);
            }

            if status.as_u16() == 429 {
                error!("è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè§¦å‘é™æµ");
                return Err(ModelError::RateLimit);
            }

            return Err(ModelError::ApiError(format!(
                "è¯·æ±‚å¤±è´¥: {} - {}",
                status, response_text
            )));
        }

        let chat_response: ChatResponse = serde_json::from_str(&response_text).map_err(|e| {
            warn!("è§£æ AutoGLM å“åº”å¤±è´¥: {}", e);
            warn!("å“åº”å†…å®¹: {}", &response_text);
            ModelError::ParseError(format!("è§£æå“åº”å¤±è´¥: {}", e))
        })?;

        Ok(chat_response)
    }

    /// è§£æ AutoGLM å“åº”ï¼ˆä½¿ç”¨ ActionEnum çš„é€šç”¨è§£ææ–¹æ³•ï¼‰
    fn parse_response(&self, content: &str) -> (Option<String>, Option<ActionEnum>) {
        ActionEnum::parse_from_response(content)
    }
}

#[async_trait]
impl ModelClient for AutoGLMClient {
    async fn query_with_messages(
        &self,
        messages: Vec<crate::agent::core::traits::ChatMessage>,
        screenshot: Option<&str>,
    ) -> Result<ModelResponse, ModelError> {
        debug!("æŸ¥è¯¢ AutoGLMï¼Œæ¶ˆæ¯æ•°é‡: {}", messages.len());

        let start_time = Instant::now();

        // è½¬æ¢æ¶ˆæ¯æ ¼å¼
        let mut api_messages = vec![];

        // æ‰¾åˆ°æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯çš„ç´¢å¼•ï¼ˆç”¨äºæ·»åŠ æˆªå›¾ï¼‰
        let last_user_msg_index = messages.iter().rposition(|msg| {
            matches!(msg.role, crate::agent::core::traits::MessageRole::User)
        });

        for (idx, msg) in messages.iter().enumerate() {
            let role = match msg.role {
                crate::agent::core::traits::MessageRole::System => {
                    crate::agent::llm::types::MessageRole::System
                }
                crate::agent::core::traits::MessageRole::User => {
                    crate::agent::llm::types::MessageRole::User
                }
                crate::agent::core::traits::MessageRole::Assistant => {
                    crate::agent::llm::types::MessageRole::Assistant
                }
            };

            // åªåœ¨æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ä¸­æ·»åŠ æˆªå›¾
            let is_last_user_msg = last_user_msg_index == Some(idx);

            let content = if is_last_user_msg && screenshot.is_some() {
                crate::agent::llm::types::MessageContent::Multimodal(vec![
                    crate::agent::llm::types::ContentBlock {
                        block_type: "image_url".to_string(),
                        text: None,
                        image_url: Some(crate::agent::llm::types::ImageUrl::from_base64(screenshot.unwrap())),
                    },
                    crate::agent::llm::types::ContentBlock {
                        block_type: "text".to_string(),
                        text: Some(msg.content.clone()),
                        image_url: None,
                    },
                ])
            } else {
                crate::agent::llm::types::MessageContent::Text(msg.content.clone())
            };

            api_messages.push(crate::agent::llm::types::ChatMessage { role, content });
        }

        // æ„å»ºè¯·æ±‚
        let request = ChatRequest {
            model: self.config.model_name.clone(),
            messages: api_messages,
            max_tokens: Some(self.config.max_tokens),
            temperature: Some(self.config.temperature),
            top_p: Some(self.config.top_p),
            stream: Some(false),
        };

        // å‘é€è¯·æ±‚
        let chat_response = self.send_request(request).await?;

        // è§£æå“åº”
        let choice = chat_response.choices.first().ok_or_else(|| {
            ModelError::ParseError("å“åº”ä¸­æ²¡æœ‰é€‰æ‹©é¡¹".to_string())
        })?;

        let content = match &choice.message.content {
            crate::agent::llm::types::MessageContent::Text(text) => text.clone(),
            _ => "".to_string(),
        };

        let total_time = start_time.elapsed().as_secs_f64();

        // ä½¿ç”¨ AutoGLM ç‰¹æ®Šè§£æ
        let (thinking, parsed_action) = self.parse_response(&content);

        let usage = chat_response.usage.unwrap_or(Usage {
            prompt_tokens: 0,
            completion_tokens: 0,
            total_tokens: 0,
        });

        // æ‰“å°æ€§èƒ½æŒ‡æ ‡
        info!("ğŸ“Š AutoGLM æ€§èƒ½æŒ‡æ ‡:");
        info!("   æ€»æ¨ç†æ—¶é—´: {:.3}s", total_time);
        info!("   ä½¿ç”¨ tokens: {}", usage.total_tokens);
        if let Some(ref t) = thinking {
            info!("   æ€è€ƒè¿‡ç¨‹: {}", t);
        }
        info!("   å®Œæ•´å“åº”: {}", &content);

        Ok(ModelResponse {
            content: content.clone(),
            action: parsed_action,
            confidence: 0.8,
            reasoning: thinking,
            tokens_used: usage.total_tokens,
        })
    }

    fn info(&self) -> ModelInfo {
        ModelInfo {
            name: self.config.model_name.clone(),
            provider: self.config.provider.clone(),
            supports_vision: true,
            max_tokens: self.config.max_tokens,
            context_window: 8192, // AutoGLM-Phone-9B çš„ä¸Šä¸‹æ–‡çª—å£
        }
    }
}

/// ChatResponse ç±»å‹ï¼ˆå¦‚æœæœªåœ¨ types.rs ä¸­å®šä¹‰ï¼‰
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChatResponse {
    pub id: Option<String>,
    pub object: Option<String>,
    pub created: Option<u64>,
    pub model: Option<String>,
    pub choices: Vec<Choice>,
    pub usage: Option<Usage>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Choice {
    pub index: usize,
    pub message: crate::agent::llm::types::ChatMessage,
    pub finish_reason: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Usage {
    pub prompt_tokens: u32,
    pub completion_tokens: u32,
    pub total_tokens: u32,
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::agent::core::traits::Action;

    #[test]
    fn test_parse_finish_action() {
        let client = AutoGLMClient::new(ModelConfig::default()).unwrap();
        let response = r#"Thinking...
finish(message="Task completed successfully")"#;

        let (thinking, action) = client.parse_response(response);

        // éªŒè¯ action è§£ææˆåŠŸ
        assert!(action.is_some());
        // éªŒè¯ action ç±»å‹ä¸º FinishAction
        assert_eq!(action.as_ref().unwrap().action_type(), "finish");
        // thinking å¯èƒ½æ˜¯ Noneï¼ˆå› ä¸ºæ²¡æœ‰ <thinking> æ ‡ç­¾ï¼‰
        assert!(thinking.is_none() || thinking.as_ref().unwrap() == "Thinking...");
    }

    #[test]
    fn test_parse_do_action() {
        let client = AutoGLMClient::new(ModelConfig::default()).unwrap();
        let response = r#"Analyzing screen...
do(action="Tap", element=[500, 800])"#;

        let (thinking, action) = client.parse_response(response);

        // éªŒè¯ thinking éƒ¨åˆ†ï¼ˆåº”è¯¥æ˜¯ Noneï¼Œå› ä¸ºæ²¡æœ‰ <thinking> æ ‡ç­¾ï¼‰
        assert!(thinking.is_none());

        // éªŒè¯ action è§£ææˆåŠŸ
        assert!(action.is_some());
        // éªŒè¯ action ç±»å‹ä¸º TapAction
        assert_eq!(action.as_ref().unwrap().action_type(), "tap");
    }

    #[test]
    fn test_parse_thinking_with_do() {
        let client = AutoGLMClient::new(ModelConfig::default()).unwrap();
        let response = r#"<thinking>I should tap the button at coordinates 100, 200</thinking>
do(action="Tap", element=[100, 200])"#;

        let (thinking, action) = client.parse_response(response);

        // éªŒè¯ thinking éƒ¨åˆ†ï¼ˆä» <thinking> æ ‡ç­¾æå–ï¼‰
        assert_eq!(thinking, Some("I should tap the button at coordinates 100, 200".to_string()));

        // éªŒè¯ action è§£ææˆåŠŸ
        assert!(action.is_some());
        // éªŒè¯ action ç±»å‹ä¸º TapAction
        assert_eq!(action.as_ref().unwrap().action_type(), "tap");
    }

    #[test]
    fn test_parse_no_markers() {
        let client = AutoGLMClient::new(ModelConfig::default()).unwrap();
        let response = r#"Some random text without markers"#;

        let (thinking, action) = client.parse_response(response);

        // thinking åº”è¯¥ä¸º Noneï¼ˆæ²¡æœ‰ <thinking> æ ‡ç­¾ï¼‰ï¼Œaction åº”è¯¥ä¸º None
        assert!(thinking.is_none());
        assert!(action.is_none());
    }

    #[test]
    fn test_parse_priority() {
        let client = AutoGLMClient::new(ModelConfig::default()).unwrap();

        // finish(message= ä¼˜å…ˆçº§æœ€é«˜
        let response1 = r#"Text...
do(action=tap)
finish(message="done")"#;
        let (thinking, action) = client.parse_response(response1);
        // thinking åº”è¯¥æ˜¯ Noneï¼ˆæ²¡æœ‰ <thinking> æ ‡ç­¾ï¼‰
        assert!(thinking.is_none());
        assert_eq!(action.unwrap().action_type(), "finish");

        // do(action= ç¬¬äºŒä¼˜å…ˆçº§
        let response2 = r#"<thinking>Thought</thinking>
<answer>answer content</answer>
do(action="Launch", app="å¾®ä¿¡")"#;
        let (thinking, action) = client.parse_response(response2);
        // thinking åº”è¯¥æ˜¯ Some("Thought")
        assert_eq!(thinking, Some("Thought".to_string()));
        assert_eq!(action.unwrap().action_type(), "launch");
    }

    #[test]
    fn test_parse_do_action_launch() {
        let client = AutoGLMClient::new(ModelConfig::default()).unwrap();
        let response = r#"I need to open WeChat.
do(action="Launch", app="å¾®ä¿¡")"#;

        println!("Testing response: {:?}", response);
        let (thinking, action) = client.parse_response(response);

        println!("Got thinking: {:?}", thinking);
        println!("Got action: {:?}", action);

        // thinking åº”è¯¥æ˜¯ Noneï¼ˆå› ä¸ºæ²¡æœ‰ <thinking> æ ‡ç­¾ï¼‰
        assert!(thinking.is_none());
        assert!(action.is_some());
        // éªŒè¯ action ç±»å‹ä¸º LaunchAction
        assert_eq!(action.as_ref().unwrap().action_type(), "launch");
    }

    #[test]
    fn test_parse_do_action_wait() {
        let client = AutoGLMClient::new(ModelConfig::default()).unwrap();
        let response = r#"åº”ç”¨æ­£åœ¨åŠ è½½ä¸­
do(action="Wait", duration=1, message="åº”ç”¨æ­£åœ¨åŠ è½½ä¸­ï¼Œè¯·ç¨ç­‰ã€‚")"#;

        let (thinking, action) = client.parse_response(response);

        // thinking åº”è¯¥æ˜¯ Noneï¼ˆæ²¡æœ‰ <thinking> æ ‡ç­¾ï¼‰
        assert!(thinking.is_none());
        assert!(action.is_some());
        // éªŒè¯ action ç±»å‹ä¸º WaitAction
        assert_eq!(action.as_ref().unwrap().action_type(), "wait");
    }

    #[test]
    fn test_parse_finish_multiline() {
        let client = AutoGLMClient::new(ModelConfig::default()).unwrap();
        let response = r#"finish(message="æŠ±æ­‰ï¼Œæˆ‘æ— æ³•æ‰¾åˆ°"ä»€ä¹ˆå€¼å¾—ä¹°"è¿™ä¸ªåº”ç”¨ã€‚

ä¸è¿‡ï¼Œæˆ‘å¯ä»¥ä¸ºæ‚¨æ‰“å¼€ä¸€äº›ç±»ä¼¼çš„åº”ç”¨æ¥æµè§ˆè´­ç‰©æˆ–æ¨èå†…å®¹ï¼Œæ¯”å¦‚ï¼š
- æ·˜å®
- ç¾å›¢

æ‚¨æƒ³æ‰“å¼€å“ªä¸ªåº”ç”¨æ¥æµè§ˆï¼Ÿ")"#;

        let (thinking, action) = client.parse_response(response);

        // thinking åº”è¯¥æ˜¯ Noneï¼ˆæ²¡æœ‰ <thinking> æ ‡ç­¾ï¼‰
        assert!(thinking.is_none());
        assert!(action.is_some());
        // éªŒè¯ action ç±»å‹ä¸º FinishAction
        assert_eq!(action.as_ref().unwrap().action_type(), "finish");

        // éªŒè¯å¤šè¡Œæ¶ˆæ¯è¢«æ­£ç¡®è§£æ
        if let Some(ActionEnum::Finish(finish)) = action {
            assert!(finish.result.contains("æŠ±æ­‰ï¼Œæˆ‘æ— æ³•æ‰¾åˆ°"));
            assert!(finish.result.contains("ä»€ä¹ˆå€¼å¾—ä¹°"));
            assert!(finish.result.contains("æ·˜å®"));
            assert!(finish.result.contains("ç¾å›¢"));
        } else {
            panic!("Expected FinishAction");
        }
    }
}
