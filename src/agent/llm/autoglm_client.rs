use async_trait::async_trait;
use reqwest::Client;
use std::time::{Duration, Instant};
use tracing::{debug, info, warn, error};
use tokio_stream::StreamExt;
use crate::agent::core::traits::{ModelClient, ModelResponse, ModelError, ModelInfo, ChatMessage, MessageRole};
use crate::agent::llm::types::{ChatRequest, ModelConfig, MessageContent, ChatMessage as ApiChatMessage, MessageRole as ApiMessageRole};
use crate::agent::llm::prompts;
use serde::{Deserialize, Serialize};

// å¯¼å…¥ ActionEnum ç”¨äºè§£æå“åº”
use crate::agent::actions::base::ActionEnum;

/// AutoGLM æµå¼å“åº”çš„å¢é‡æ•°æ®
#[derive(Debug, Deserialize)]
#[serde(tag = "type")]
enum StreamEvent {
    #[serde(rename = "token")]
    Token { token: String },
    #[serde(rename = "message_end")]
    MessageEnd,
}

/// AutoGLM æ€§èƒ½æŒ‡æ ‡
#[derive(Debug, Clone, Serialize)]
pub struct PerformanceMetrics {
    /// é¦–ä¸ª token æ—¶é—´ï¼ˆç§’ï¼‰
    pub time_to_first_token: Option<f64>,
    /// æ€è€ƒç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰
    pub time_to_thinking_end: Option<f64>,
    /// æ€»æ¨ç†æ—¶é—´ï¼ˆç§’ï¼‰
    pub total_time: f64,
}

/// AutoGLM å®¢æˆ·ç«¯ï¼Œæ”¯æŒæµå¼å“åº”å’Œç‰¹æ®Šæ ‡è®°è§£æ
pub struct AutoGLMClient {
    /// ä¸»å®¢æˆ·ç«¯ï¼Œç”¨äºä¸»è¦æ“ä½œå†³ç­–
    client: Client,
    /// è¾…åŠ©å®¢æˆ·ç«¯ï¼Œç”¨äºä¿®æ­£å’Œè§„èŒƒåŒ–ä¸»æ¨¡å‹çš„è¾“å‡º
    auxiliary_client: Client,
    /// æ¨¡å‹é…ç½®
    config: ModelConfig,
}

impl AutoGLMClient {
    /// åˆ›å»ºæ–°çš„ AutoGLM å®¢æˆ·ç«¯
    pub fn new(config: ModelConfig) -> Result<Self, ModelError> {
        info!("åˆ›å»º AutoGLM å®¢æˆ·ç«¯: {}", config.model_name);
        info!("  API ç«¯ç‚¹: {}", config.base_url);
        info!("  è¶…æ—¶æ—¶é—´: {}s", config.timeout);
        info!("  API Key: {}...", &config.api_key[..config.api_key.len().min(10)]);

        // æ˜¾ç¤ºè¾…åŠ©æ¨¡å‹é…ç½®
        if let Some(ref aux_name) = config.auxiliary_model_name {
            info!("  è¾…åŠ©æ¨¡å‹: {}", aux_name);
        } else {
            info!("  æœªé…ç½®è¾…åŠ©æ¨¡å‹");
        }

        let client = Client::builder()
            .timeout(Duration::from_secs(config.timeout))
            .connect_timeout(Duration::from_secs(30))
            .pool_idle_timeout(Duration::from_secs(120))
            .tcp_keepalive(Duration::from_secs(600))
            .build()
            .map_err(|e| ModelError::ApiError(format!("åˆ›å»º HTTP å®¢æˆ·ç«¯å¤±è´¥: {}", e)))?;

        // åˆ›å»ºè¾…åŠ©å®¢æˆ·ç«¯ï¼ˆä½¿ç”¨ç›¸åŒçš„é…ç½®ï¼‰
        let auxiliary_client = Client::builder()
            .timeout(Duration::from_secs(config.timeout))
            .connect_timeout(Duration::from_secs(30))
            .pool_idle_timeout(Duration::from_secs(120))
            .tcp_keepalive(Duration::from_secs(600))
            .build()
            .map_err(|e| ModelError::ApiError(format!("åˆ›å»ºè¾…åŠ© HTTP å®¢æˆ·ç«¯å¤±è´¥: {}", e)))?;

        Ok(Self {
            client,
            auxiliary_client,
            config,
        })
    }

    /// å‘é€æµå¼èŠå¤©è¯·æ±‚
    async fn send_stream_request(&self, request: ChatRequest) -> Result<String, ModelError> {
        let url = format!("{}/chat/completions", self.config.base_url);

        debug!("å‘é€ AutoGLM æµå¼è¯·æ±‚åˆ°: {}", url);

        let mut stream_request = request.clone();
        stream_request.stream = Some(true);

        let response = self
            .client
            .post(&url)
            .header("Authorization", format!("Bearer {}", self.config.api_key))
            .header("Content-Type", "application/json")
            .json(&stream_request)
            .send()
            .await
            .map_err(|e| ModelError::NetworkError(format!("å‘é€è¯·æ±‚å¤±è´¥: {}", e)))?;

        let status = response.status();

        if !status.is_success() {
            let error_text = response
                .text()
                .await
                .unwrap_or_else(|_| "æ— æ³•è¯»å–é”™è¯¯å“åº”".to_string());

            error!("AutoGLM è¯·æ±‚å¤±è´¥: {} - {}", status, error_text);

            if status.as_u16() == 401 {
                return Err(ModelError::InvalidApiKey);
            }

            if status.as_u16() == 429 {
                return Err(ModelError::RateLimit);
            }

            return Err(ModelError::ApiError(format!(
                "è¯·æ±‚å¤±è´¥: {} - {}",
                status, error_text
            )));
        }

        // å¤„ç†æµå¼å“åº”
        let mut full_content = String::new();
        let mut byte_stream = response.bytes_stream();

        while let Some(chunk_result) = byte_stream.next().await {
            let chunk = chunk_result
                .map_err(|e| ModelError::NetworkError(format!("è¯»å–æµæ•°æ®å¤±è´¥: {}", e)))?;

            let chunk_str = String::from_utf8_lossy(&chunk);
            full_content.push_str(&chunk_str);
        }

        Ok(full_content)
    }

    /// å‘é€éæµå¼èŠå¤©è¯·æ±‚
    async fn send_request(&self, request: ChatRequest) -> Result<ChatResponse, ModelError> {
        let url = format!("{}/chat/completions", self.config.base_url);

        info!("å‘é€ AutoGLM è¯·æ±‚åˆ°: {}", url);
        info!("  æ¨¡å‹: {}", request.model);
        info!("  æ¶ˆæ¯æ•°: {}", request.messages.len());

        // å‘é€è¯·æ±‚å¹¶å¤„ç†é”™è¯¯
        match self._send_request(&url, &request, &self.client, &self.config.api_key).await {
            Ok(response) => Ok(response),
            Err(e) => {
                error!("AutoGLM è¯·æ±‚å¤±è´¥: {}", e);
                error!("è¯·æ£€æŸ¥:");
                error!("  1. API Key æ˜¯å¦æ­£ç¡®è®¾ç½®");
                error!("  2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸");
                error!("  3. API ç«¯ç‚¹æ˜¯å¦å¯è®¿é—®: {}", self.config.base_url);
                error!("  4. æ˜¯å¦æœ‰è¶³å¤Ÿçš„é…é¢");
                Err(e)
            }
        }
    }

    /// ä½¿ç”¨è¾…åŠ©æ¨¡å‹å‘é€è¯·æ±‚ä»¥ä¿®æ­£å“åº”
    async fn send_auxiliary_request(&self, original_content: &str) -> Result<String, ModelError> {
        // å¦‚æœæ²¡æœ‰é…ç½®è¾…åŠ©æ¨¡å‹åç§°ï¼Œç›´æ¥è¿”å›åŸå§‹å†…å®¹
        let aux_model_name = match &self.config.auxiliary_model_name {
            Some(name) => name,
            None => {
                debug!("æœªé…ç½®è¾…åŠ©æ¨¡å‹ï¼Œè·³è¿‡å“åº”ä¿®æ­£");
                return Ok(original_content.to_string());
            }
        };

        info!("ä½¿ç”¨è¾…åŠ©æ¨¡å‹ä¿®æ­£å“åº”: {}", aux_model_name);

        let url = format!("{}/chat/completions", self.config.base_url);

        // æ„å»ºè¾…åŠ©æ¨¡å‹è¯·æ±‚
        let system_prompt = prompts::get_auxiliary_system_prompt();
        let user_message = format!("è¯·ä¿®æ­£ä»¥ä¸‹è¾“å‡ºï¼Œä½¿å…¶ç¬¦åˆæ ¼å¼è¦æ±‚ï¼š\n\n{}", original_content);

        let api_messages = vec![
            ApiChatMessage {
                role: ApiMessageRole::System,
                content: MessageContent::Text(system_prompt),
            },
            ApiChatMessage {
                role: ApiMessageRole::User,
                content: MessageContent::Text(user_message),
            },
        ];

        let request = ChatRequest {
            model: aux_model_name.clone(),
            messages: api_messages,
            max_tokens: Some(2048),
            temperature: Some(0.0),
            top_p: Some(0.85),
            stream: Some(false),
        };

        let chat_response = self._send_request(&url, &request, &self.auxiliary_client, &self.config.api_key).await?;

        // æå–ä¿®æ­£åçš„å†…å®¹
        let choice = chat_response.choices.first().ok_or_else(|| {
            ModelError::ParseError("è¾…åŠ©æ¨¡å‹å“åº”ä¸­æ²¡æœ‰é€‰æ‹©é¡¹".to_string())
        })?;

        let corrected_content = match &choice.message.content {
            MessageContent::Text(text) => text.clone(),
            _ => original_content.to_string(),
        };

        info!("è¾…åŠ©æ¨¡å‹ä¿®æ­£å®Œæˆ");
        debug!("åŸå§‹å†…å®¹: {}", original_content);
        debug!("ä¿®æ­£åå†…å®¹: {}", corrected_content);

        Ok(corrected_content)
    }

    async fn _send_request(
        &self,
        url: &str,
        request: &ChatRequest,
        client: &Client,
        api_key: &str,
    ) -> Result<ChatResponse, ModelError> {
        // æ‰“å°è¯·æ±‚è¯¦æƒ…ï¼ˆé€‰æ‹©æ€§è¾“å‡ºï¼Œè¿‡æ»¤å›¾ç‰‡æ•°æ®ï¼‰
        info!("========== AutoGLM è¯·æ±‚ ==========");
        info!("URL: {}", url);
        info!("æ¨¡å‹: {}", request.model);
        info!("å‚æ•°: max_tokens={:?}, temperature={:?}, top_p={:?}, stream={:?}",
            request.max_tokens, request.temperature, request.top_p, request.stream);
        info!("æ¶ˆæ¯æ•°é‡: {}", request.messages.len());
        info!("================================");

        let response = client
            .post(url)
            .header("Authorization", format!("Bearer {}", api_key))
            .header("Content-Type", "application/json")
            .json(request)
            .send()
            .await
            .map_err(|e| {
                error!("ğŸ”´ AutoGLM ç½‘ç»œè¯·æ±‚å¤±è´¥");
                error!("   URL: {}", url);
                error!("   é”™è¯¯ç±»å‹: {:?}", e);

                // æä¾›æ›´è¯¦ç»†çš„è¯Šæ–­ä¿¡æ¯
                if e.is_timeout() {
                    error!("   é”™è¯¯: è¯·æ±‚è¶…æ—¶");
                    error!("   å¯èƒ½çš„åŸå› :");
                    error!("   1. ç½‘ç»œè¿æ¥ä¸ç¨³å®š");
                    error!("   2. API æœåŠ¡å™¨å“åº”ç¼“æ…¢");
                    error!("   3. è¯·æ±‚å¤ªå¤§ï¼Œå¤„ç†æ—¶é—´è¿‡é•¿");
                    error!("   å»ºè®®:");
                    error!("   - æ£€æŸ¥ç½‘ç»œè¿æ¥");
                    error!("   - å¢åŠ  timeout æ—¶é—´");
                    error!("   - å‡å°è¯·æ±‚å¤§å°ï¼ˆå¦‚å‡å°‘å›¾ç‰‡æ•°é‡ï¼‰");
                } else if e.is_connect() {
                    error!("   é”™è¯¯: æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨");
                    error!("   å¯èƒ½çš„åŸå› :");
                    error!("   1. ç½‘ç»œæœªè¿æ¥");
                    error!("   2. API æœåŠ¡å™¨åœ°å€é”™è¯¯: {}", url);
                    error!("   3. é˜²ç«å¢™æˆ–ä»£ç†é˜»æ­¢è¿æ¥");
                    error!("   4. DNS è§£æå¤±è´¥");
                    error!("   å»ºè®®:");
                    error!("   - æ£€æŸ¥ç½‘ç»œè¿æ¥");
                    error!("   - éªŒè¯ API URL æ˜¯å¦æ­£ç¡®");
                    error!("   - æ£€æŸ¥é˜²ç«å¢™è®¾ç½®");
                    error!("   - å°è¯•ä½¿ç”¨ VPN");
                } else {
                    error!("   å…¶ä»–ç½‘ç»œé”™è¯¯");
                    error!("   åŸå§‹é”™è¯¯: {}", e);
                }

                ModelError::NetworkError(format!("å‘é€è¯·æ±‚å¤±è´¥: {}", e))
            })?;

        let status = response.status();
        debug!("å“åº”çŠ¶æ€: {}", status);

        let response_text = response
            .text()
            .await
            .map_err(|e| ModelError::NetworkError(format!("è¯»å–å“åº”å¤±è´¥: {}", e)))?;

        // æ‰“å°å“åº”è¯¦æƒ…
        info!("========== AutoGLM å“åº” ==========");
        info!("çŠ¶æ€ç : {}", status);
        info!("å“åº”ä½“ ({} å­—èŠ‚):", response_text.len());
        info!("================================");

        if !status.is_success() {
            warn!("AutoGLM è¯·æ±‚å¤±è´¥: {} - {}", status, response_text);

            if status.as_u16() == 401 {
                error!("API Key æ— æ•ˆ");
                return Err(ModelError::InvalidApiKey);
            }

            if status.as_u16() == 429 {
                error!("è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè§¦å‘é™æµ");
                return Err(ModelError::RateLimit);
            }

            return Err(ModelError::ApiError(format!(
                "è¯·æ±‚å¤±è´¥: {} - {}",
                status, response_text
            )));
        }

        let chat_response: ChatResponse = serde_json::from_str(&response_text).map_err(|e| {
            warn!("è§£æ AutoGLM å“åº”å¤±è´¥: {}", e);
            warn!("å“åº”å†…å®¹: {}", &response_text);
            ModelError::ParseError(format!("è§£æå“åº”å¤±è´¥: {}", e))
        })?;

        Ok(chat_response)
    }

    /// è§£æ AutoGLM å“åº”ï¼ˆä½¿ç”¨ ActionEnum çš„é€šç”¨è§£ææ–¹æ³•ï¼‰
    fn parse_response(&self, content: &str) -> (Option<String>, Vec<ActionEnum>) {
        ActionEnum::parse_from_response(content)
    }
}

#[async_trait]
impl ModelClient for AutoGLMClient {
    async fn query_with_messages(
        &self,
        messages: Vec<ChatMessage>,
        screenshot: Option<&str>,
    ) -> Result<ModelResponse, ModelError> {
        debug!("æŸ¥è¯¢ AutoGLMï¼Œæ¶ˆæ¯æ•°é‡: {}", messages.len());

        let start_time = Instant::now();

        // è½¬æ¢æ¶ˆæ¯æ ¼å¼
        let mut api_messages = vec![];

        // æ‰¾åˆ°æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯çš„ç´¢å¼•ï¼ˆç”¨äºæ·»åŠ æˆªå›¾ï¼‰
        let last_user_msg_index = messages.iter().rposition(|msg| {
            matches!(msg.role, MessageRole::User)
        });

        for (idx, msg) in messages.iter().enumerate() {
            let role = match msg.role {
                MessageRole::System => ApiMessageRole::System,
                MessageRole::User => ApiMessageRole::User,
                MessageRole::Assistant => ApiMessageRole::Assistant,
            };

            // åªåœ¨æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ä¸­æ·»åŠ æˆªå›¾
            let is_last_user_msg = last_user_msg_index == Some(idx);

            let content = if is_last_user_msg && screenshot.is_some() {
                MessageContent::Multimodal(vec![
                    crate::agent::llm::types::ContentBlock {
                        block_type: "image_url".to_string(),
                        text: None,
                        image_url: Some(crate::agent::llm::types::ImageUrl::from_base64(screenshot.unwrap())),
                    },
                    crate::agent::llm::types::ContentBlock {
                        block_type: "text".to_string(),
                        text: Some(msg.content.clone()),
                        image_url: None,
                    },
                ])
            } else {
                MessageContent::Text(msg.content.clone())
            };

            api_messages.push(ApiChatMessage { role, content });
        }

        // æ„å»ºè¯·æ±‚
        let request = ChatRequest {
            model: self.config.model_name.clone(),
            messages: api_messages,
            max_tokens: Some(self.config.max_tokens),
            temperature: Some(self.config.temperature),
            top_p: Some(self.config.top_p),
            stream: Some(false),
        };

        // å‘é€è¯·æ±‚
        let chat_response = self.send_request(request).await?;

        // è§£æå“åº”
        let choice = chat_response.choices.first().ok_or_else(|| {
            ModelError::ParseError("å“åº”ä¸­æ²¡æœ‰é€‰æ‹©é¡¹".to_string())
        })?;

        let mut content = match &choice.message.content {
            MessageContent::Text(text) => text.clone(),
            _ => "".to_string(),
        };

        // ä½¿ç”¨è¾…åŠ©æ¨¡å‹ä¼˜åŒ–å“åº”ï¼ˆå¦‚æœé…ç½®äº†è¾…åŠ©æ¨¡å‹åç§°ï¼‰
        if self.config.auxiliary_model_name.is_some() {
            info!("ä¸»æ¨¡å‹å“åº”æ— æ³•è§£æï¼Œä½¿ç”¨è¾…åŠ©æ¨¡å‹ä¿®æ­£");
            match self.send_auxiliary_request(&content).await {
                Ok(corrected_content) => {
                    content = corrected_content;
                },
                Err(e) => {
                    warn!("è¾…åŠ©æ¨¡å‹ä¿®æ­£å¤±è´¥: {}, ä½¿ç”¨åŸå§‹å“åº”", e);
                    // ç»§ç»­ä½¿ç”¨åŸå§‹å“åº”
                }
            }
        }

        let total_time = start_time.elapsed().as_secs_f64();

        // ä½¿ç”¨ AutoGLM ç‰¹æ®Šè§£æ
        let (thinking, parsed_actions) = self.parse_response(&content);

        let usage = chat_response.usage.unwrap_or(Usage {
            prompt_tokens: 0,
            completion_tokens: 0,
            total_tokens: 0,
        });

        // æ‰“å°æ€§èƒ½æŒ‡æ ‡
        info!("ğŸ“Š AutoGLM æ€§èƒ½æŒ‡æ ‡:");
        info!("   æ€»æ¨ç†æ—¶é—´: {:.3}s", total_time);
        info!("   ä½¿ç”¨ tokens: {}", usage.total_tokens);
        if let Some(ref t) = thinking {
            info!("   æ€è€ƒè¿‡ç¨‹: {}", t);
        }
        info!("   è§£æåˆ°çš„æ“ä½œæ•°: {}", parsed_actions.len());
        info!("   å®Œæ•´å“åº”: {}", &content);

        Ok(ModelResponse {
            content: content.clone(),
            actions: parsed_actions,
            confidence: 0.8,
            reasoning: thinking,
            tokens_used: usage.total_tokens,
        })
    }

    fn info(&self) -> ModelInfo {
        ModelInfo {
            name: self.config.model_name.clone(),
            provider: self.config.provider.clone(),
            supports_vision: true,
            max_tokens: self.config.max_tokens,
            context_window: 8192, // AutoGLM-Phone-9B çš„ä¸Šä¸‹æ–‡çª—å£
        }
    }
}

/// ChatResponse ç±»å‹ï¼ˆå¦‚æœæœªåœ¨ types.rs ä¸­å®šä¹‰ï¼‰
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChatResponse {
    pub id: Option<String>,
    pub object: Option<String>,
    pub created: Option<u64>,
    pub model: Option<String>,
    pub choices: Vec<Choice>,
    pub usage: Option<Usage>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Choice {
    pub index: usize,
    pub message: ApiChatMessage,
    pub finish_reason: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Usage {
    pub prompt_tokens: u32,
    pub completion_tokens: u32,
    pub total_tokens: u32,
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::agent::core::traits::Action;

    #[test]
    fn test_parse_finish_action() {
        let client = AutoGLMClient::new(ModelConfig::default()).unwrap();
        let response = r#"Thinking...
finish(message="Task completed successfully")"#;

        let (thinking, actions) = client.parse_response(response);

        // éªŒè¯ action è§£ææˆåŠŸ
        assert!(!actions.is_empty());
        assert_eq!(actions.len(), 1);
        // éªŒè¯ action ç±»å‹ä¸º FinishAction
        assert_eq!(actions[0].action_type(), "finish");
        // thinking å¯èƒ½æ˜¯ Noneï¼ˆå› ä¸ºæ²¡æœ‰ <thinking> æ ‡ç­¾ï¼‰
        assert!(thinking.is_none() || thinking.as_ref().unwrap() == "Thinking...");
    }

    #[test]
    fn test_parse_do_action() {
        let client = AutoGLMClient::new(ModelConfig::default()).unwrap();
        let response = r#"Analyzing screen...
do(action="Tap", element=[500, 800])"#;

        let (thinking, actions) = client.parse_response(response);

        // éªŒè¯ thinking éƒ¨åˆ†ï¼ˆåº”è¯¥æ˜¯ Noneï¼Œå› ä¸ºæ²¡æœ‰ <thinking> æ ‡ç­¾ï¼‰
        assert!(thinking.is_none());

        // éªŒè¯ action è§£ææˆåŠŸ
        assert!(!actions.is_empty());
        assert_eq!(actions.len(), 1);
        // éªŒè¯ action ç±»å‹ä¸º TapAction
        assert_eq!(actions[0].action_type(), "tap");
    }

    #[test]
    fn test_parse_thinking_with_do() {
        let client = AutoGLMClient::new(ModelConfig::default()).unwrap();
        let response = r#"<thinking>I should tap the button at coordinates 100, 200</thinking>
do(action="Tap", element=[100, 200])"#;

        let (thinking, actions) = client.parse_response(response);

        // éªŒè¯ thinking éƒ¨åˆ†ï¼ˆä» <thinking> æ ‡ç­¾æå–ï¼‰
        assert_eq!(thinking, Some("I should tap the button at coordinates 100, 200".to_string()));

        // éªŒè¯ action è§£ææˆåŠŸ
        assert!(!actions.is_empty());
        assert_eq!(actions.len(), 1);
        // éªŒè¯ action ç±»å‹ä¸º TapAction
        assert_eq!(actions[0].action_type(), "tap");
    }

    #[test]
    fn test_parse_no_markers() {
        let client = AutoGLMClient::new(ModelConfig::default()).unwrap();
        let response = r#"Some random text without markers"#;

        let (thinking, actions) = client.parse_response(response);

        // thinking åº”è¯¥ä¸º Noneï¼ˆæ²¡æœ‰ <thinking> æ ‡ç­¾ï¼‰ï¼Œactions åº”è¯¥ä¸ºç©º
        assert!(thinking.is_none());
        assert!(actions.is_empty());
    }

    #[test]
    fn test_parse_priority() {
        let client = AutoGLMClient::new(ModelConfig::default()).unwrap();

        // finish(message= ä¼˜å…ˆçº§æœ€é«˜
        let response1 = r#"Text...
do(action=tap)
finish(message="done")"#;
        let (thinking, actions) = client.parse_response(response1);
        // thinking åº”è¯¥æ˜¯ Noneï¼ˆæ²¡æœ‰ <thinking> æ ‡ç­¾ï¼‰
        assert!(thinking.is_none());
        assert_eq!(actions.len(), 1);
        assert_eq!(actions[0].action_type(), "finish");

        // do(action= ç¬¬äºŒä¼˜å…ˆçº§
        let response2 = r#"<thinking>Thought</thinking>
<answer>answer content</answer>
do(action="Launch", app="å¾®ä¿¡")"#;
        let (thinking, actions) = client.parse_response(response2);
        // thinking åº”è¯¥æ˜¯ Some("Thought")
        assert_eq!(thinking, Some("Thought".to_string()));
        assert_eq!(actions.len(), 1);
        assert_eq!(actions[0].action_type(), "launch");
    }

    #[test]
    fn test_parse_do_action_launch() {
        let client = AutoGLMClient::new(ModelConfig::default()).unwrap();
        let response = r#"I need to open WeChat.
do(action="Launch", app="å¾®ä¿¡")"#;

        println!("Testing response: {:?}", response);
        let (thinking, actions) = client.parse_response(response);

        println!("Got thinking: {:?}", thinking);
        println!("Got actions: {:?}", actions);

        // thinking åº”è¯¥æ˜¯ Noneï¼ˆå› ä¸ºæ²¡æœ‰ <thinking> æ ‡ç­¾ï¼‰
        assert!(thinking.is_none());
        assert!(!actions.is_empty());
        // éªŒè¯ action ç±»å‹ä¸º LaunchAction
        assert_eq!(actions[0].action_type(), "launch");
    }

    #[test]
    fn test_parse_do_action_wait() {
        let client = AutoGLMClient::new(ModelConfig::default()).unwrap();
        let response = r#"åº”ç”¨æ­£åœ¨åŠ è½½ä¸­
do(action="Wait", duration=1, message="åº”ç”¨æ­£åœ¨åŠ è½½ä¸­ï¼Œè¯·ç¨ç­‰ã€‚")"#;

        let (thinking, actions) = client.parse_response(response);

        // thinking åº”è¯¥æ˜¯ Noneï¼ˆæ²¡æœ‰ <thinking> æ ‡ç­¾ï¼‰
        assert!(thinking.is_none());
        assert!(!actions.is_empty());
        // éªŒè¯ action ç±»å‹ä¸º WaitAction
        assert_eq!(actions[0].action_type(), "wait");
    }

    #[test]
    fn test_parse_finish_multiline() {
        let client = AutoGLMClient::new(ModelConfig::default()).unwrap();
        let response = r#"finish(message="æŠ±æ­‰ï¼Œæˆ‘æ— æ³•æ‰¾åˆ°"ä»€ä¹ˆå€¼å¾—ä¹°"è¿™ä¸ªåº”ç”¨ã€‚

ä¸è¿‡ï¼Œæˆ‘å¯ä»¥ä¸ºæ‚¨æ‰“å¼€ä¸€äº›ç±»ä¼¼çš„åº”ç”¨æ¥æµè§ˆè´­ç‰©æˆ–æ¨èå†…å®¹ï¼Œæ¯”å¦‚ï¼š
- æ·˜å®
- ç¾å›¢

æ‚¨æƒ³æ‰“å¼€å“ªä¸ªåº”ç”¨æ¥æµè§ˆï¼Ÿ")"#;

        let (thinking, actions) = client.parse_response(response);

        // thinking åº”è¯¥æ˜¯ Noneï¼ˆæ²¡æœ‰ <thinking> æ ‡ç­¾ï¼‰
        assert!(thinking.is_none());
        assert!(!actions.is_empty());
        // éªŒè¯ action ç±»å‹ä¸º FinishAction
        assert_eq!(actions[0].action_type(), "finish");

        // éªŒè¯å¤šè¡Œæ¶ˆæ¯è¢«æ­£ç¡®è§£æ
        if let ActionEnum::Finish(ref finish) = actions[0] {
            assert!(finish.result.contains("æŠ±æ­‰ï¼Œæˆ‘æ— æ³•æ‰¾åˆ°"));
            assert!(finish.result.contains("ä»€ä¹ˆå€¼å¾—ä¹°"));
            assert!(finish.result.contains("æ·˜å®"));
            assert!(finish.result.contains("ç¾å›¢"));
        } else {
            panic!("Expected FinishAction");
        }
    }
}
